{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obl0C1YkKIEm",
        "outputId": "5e31670f-81d9-447d-c63b-63e3037bc4c1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-ZpD7cJH_pA"
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX9oWmROKf2v"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/Flower Recognition\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Bsau1pwRdPA"
      },
      "source": [
        "DAISY_SOURCE_DIR = \"/content/drive/MyDrive/Flower Recognition/Original Dataset/daisy/\"\n",
        "TRAIN_DAISY_DIR = \"/content/drive/MyDrive/Flower Recognition/Splitted/TRAIN/daisy/\"\n",
        "TEST_DAISY_DIR = \"/content/drive/MyDrive/Flower Recognition/Splitted/TEST/daisy/\"\n",
        "VAL_DAISY_DIR = \"/content/drive/MyDrive/Flower Recognition/Splitted/VAL/daisy/\"\n",
        "\n",
        "DANDELION_SOURCE_DIR = \"/content/drive/MyDrive/Flower Recognition/Original Dataset/dandelion/\"\n",
        "TRAIN_DANDELION_DIR = \"/content/drive/MyDrive/Flower Recognition/Splitted/TRAIN/dandelion/\"\n",
        "TEST_DANDELION_DIR = \"/content/drive/MyDrive/Flower Recognition/Splitted/TEST/dandelion/\"\n",
        "VAL_DANDELION_DIR = \"/content/drive/MyDrive/Flower Recognition/Splitted/VAL/dandelion/\"\n",
        "\n",
        "ROSE_SOURCE_DIR = \"/content/drive/MyDrive/Flower Recognition/Original Dataset/rose/\"\n",
        "TRAIN_ROSE_DIR = \"/content/drive/MyDrive/Flower Recognition/Splitted/TRAIN/rose/\"\n",
        "TEST_ROSE_DIR = \"/content/drive/MyDrive/Flower Recognition/Splitted/TEST/rose/\"\n",
        "VAL_ROSE_DIR = \"/content/drive/MyDrive/Flower Recognition/Splitted/VAL/rose/\"\n",
        "\n",
        "SUNFLOWER_SOURCE_DIR = \"/content/drive/MyDrive/Flower Recognition/Original Dataset/sunflower/\"\n",
        "TRAIN_SUNFLOWER_DIR = \"/content/drive/MyDrive/Flower Recognition/Splitted/TRAIN/sunflower/\"\n",
        "TEST_SUNFLOWER_DIR = \"/content/drive/MyDrive/Flower Recognition/Splitted/TEST/sunflower/\"\n",
        "VAL_SUNFLOWER_DIR = \"/content/drive/MyDrive/Flower Recognition/Splitted/VAL/sunflower/\"\n",
        "\n",
        "TULIP_SOURCE_DIR = \"/content/drive/MyDrive/Flower Recognition/Original Dataset/tulip/\"\n",
        "TRAIN_TULIP_DIR = \"/content/drive/MyDrive/Flower Recognition/Splitted/TRAIN/tulip/\"\n",
        "TEST_TULIP_DIR = \"/content/drive/MyDrive/Flower Recognition/Splitted/TEST/tulip/\"\n",
        "VAL_TULIP_DIR = \"/content/drive/MyDrive/Flower Recognition/Splitted/VAL/tulip/\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7n-8YNpNNlN"
      },
      "source": [
        "Checking the number of training images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANx9kXesNM0T",
        "outputId": "97ba18d5-01e2-4f72-d9c9-40214e0cb053"
      },
      "source": [
        "print(\"Number of training daisy images\", len(os.listdir(TRAIN_DAISY_DIR)))\n",
        "print(\"Number of training dandelion images\", len(os.listdir(TRAIN_DANDELION_DIR)))\n",
        "print(\"Number of training rose images\", len(os.listdir(TRAIN_ROSE_DIR)))\n",
        "print(\"Number of training sunflower images\", len(os.listdir(TRAIN_SUNFLOWER_DIR)))\n",
        "print(\"Number of training tulip images\", len(os.listdir(TRAIN_TULIP_DIR)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training daisy images 692\n",
            "Number of training dandelion images 949\n",
            "Number of training rose images 705\n",
            "Number of training sunflower images 660\n",
            "Number of training tulip images 885\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kj4ESZRbNyZw"
      },
      "source": [
        "Checking the number of testing images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTi45Nf7Nxzg",
        "outputId": "c86c5b4e-8667-47a2-d992-f672783378e1"
      },
      "source": [
        "print(\"Number of testing daisy images\", len(os.listdir(TEST_DAISY_DIR)))\n",
        "print(\"Number of testing dandelion images\", len(os.listdir(TEST_DANDELION_DIR)))\n",
        "print(\"Number of testing rose images\", len(os.listdir(TEST_ROSE_DIR)))\n",
        "print(\"Number of testing sunflower images\", len(os.listdir(TEST_SUNFLOWER_DIR)))\n",
        "print(\"Number of testing tulip images\", len(os.listdir(TEST_TULIP_DIR)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of testing daisy images 23\n",
            "Number of testing dandelion images 31\n",
            "Number of testing rose images 23\n",
            "Number of testing sunflower images 22\n",
            "Number of testing tulip images 29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QktxUrU-WrMW"
      },
      "source": [
        "Checking the number of validation images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8EQaJs0UmbL",
        "outputId": "5892fae7-6bba-44da-b0b2-32af25da7a13"
      },
      "source": [
        "print(\"Number of validation daisy images\", len(os.listdir(VAL_DAISY_DIR)))\n",
        "print(\"Number of validation dandelion images\", len(os.listdir(VAL_DANDELION_DIR)))\n",
        "print(\"Number of validation rose images\", len(os.listdir(VAL_ROSE_DIR)))\n",
        "print(\"Number of validation sunflower images\", len(os.listdir(VAL_SUNFLOWER_DIR)))\n",
        "print(\"Number of validation tulip images\", len(os.listdir(VAL_TULIP_DIR)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of validation daisy images 54\n",
            "Number of validation dandelion images 75\n",
            "Number of validation rose images 56\n",
            "Number of validation sunflower images 52\n",
            "Number of validation tulip images 70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjOJgBrqOXTz"
      },
      "source": [
        "Setting the directories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkychBzkOOkf",
        "outputId": "3f7e9bf0-d359-4efb-a329-97fbe23d60fd"
      },
      "source": [
        "TRAINING_DIR = \"/content/drive/MyDrive/Flower Recognition/Splitted/TRAIN\"\n",
        "# Experiment with your own parameters to reach 99.9% validation accuracy or better\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n",
        "                                                    batch_size=50,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    target_size=(224, 224))\n",
        "\n",
        "VALIDATION_DIR = \"/content/drive/MyDrive/Flower Recognition/Splitted/VAL\"\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n",
        "                                                              batch_size=50,\n",
        "                                                              class_mode='categorical',\n",
        "                                                              target_size=(224, 224))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3889 images belonging to 5 classes.\n",
            "Found 307 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Vf36ThgP8Ap"
      },
      "source": [
        "Loading the pre-trained inceptionV3 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Psofi9fP7ru",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13b34563-22c7-4aaf-d3e9-cc4c676fe626"
      },
      "source": [
        "pre_trained_model = ResNet50(input_shape=(224, 224, 3),include_top=False,\n",
        "                                pooling='max', weights='imagenet',classes=5)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWgDS_hlYWuJ"
      },
      "source": [
        "print(pre_trained_model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8oAHIcjZxmE",
        "outputId": "885eed1f-d99f-46ba-a555-5de33c25c784"
      },
      "source": [
        "# freeze the layers\n",
        "for layer in pre_trained_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "last_layer = pre_trained_model.get_layer('max_pool')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 2048)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUG9VcGJaer8"
      },
      "source": [
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(last_output)\n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(5, activation='softmax')(x)\n",
        "\n",
        "model = Model(pre_trained_model.input, x)\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwtAv6ufZOst",
        "outputId": "6818e0be-d2ce-4cbe-8670-77f79ab3ede2"
      },
      "source": [
        "# compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "# train the model (adjust the number of epochs from 1 to improve performance)\n",
        "history = model.fit(\n",
        "            train_generator,\n",
        "            validation_data=validation_generator,\n",
        "            epochs=10,\n",
        "            verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "78/78 [==============================] - 1370s 17s/step - loss: 2.6308 - acc: 0.3050 - val_loss: 1.4091 - val_acc: 0.4365\n",
            "Epoch 2/10\n",
            "78/78 [==============================] - 54s 694ms/step - loss: 1.5199 - acc: 0.3772 - val_loss: 1.6167 - val_acc: 0.2801\n",
            "Epoch 3/10\n",
            "78/78 [==============================] - 55s 710ms/step - loss: 1.4838 - acc: 0.3844 - val_loss: 1.3184 - val_acc: 0.4528\n",
            "Epoch 4/10\n",
            "78/78 [==============================] - 54s 693ms/step - loss: 1.4218 - acc: 0.4150 - val_loss: 1.2764 - val_acc: 0.4951\n",
            "Epoch 5/10\n",
            "78/78 [==============================] - 54s 687ms/step - loss: 1.4343 - acc: 0.4127 - val_loss: 1.2120 - val_acc: 0.5114\n",
            "Epoch 6/10\n",
            "78/78 [==============================] - 54s 687ms/step - loss: 1.3906 - acc: 0.4230 - val_loss: 1.1981 - val_acc: 0.5212\n",
            "Epoch 7/10\n",
            "78/78 [==============================] - 53s 684ms/step - loss: 1.3707 - acc: 0.4466 - val_loss: 1.2467 - val_acc: 0.4625\n",
            "Epoch 8/10\n",
            "78/78 [==============================] - 53s 685ms/step - loss: 1.3659 - acc: 0.4374 - val_loss: 1.1752 - val_acc: 0.5147\n",
            "Epoch 9/10\n",
            "78/78 [==============================] - 53s 684ms/step - loss: 1.3649 - acc: 0.4361 - val_loss: 1.1726 - val_acc: 0.5277\n",
            "Epoch 10/10\n",
            "78/78 [==============================] - 53s 684ms/step - loss: 1.3794 - acc: 0.4315 - val_loss: 1.2442 - val_acc: 0.4951\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muPBNG2ueOw8"
      },
      "source": [
        "Testing the image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIOH4TIyj-7n",
        "outputId": "b0579814-954f-44f4-85c7-54f44124b03b"
      },
      "source": [
        "categories = np.array(['daisy','dandelion','tulip','rose','sunflower'])\n",
        "categories = np.sort(categories)\n",
        "print(categories)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['daisy' 'dandelion' 'rose' 'sunflower' 'tulip']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gr0CQav0gC_s",
        "outputId": "20dcec91-191e-4edc-9e55-e80ae3514304"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "img = image.load_img('/content/drive/MyDrive/Flower Recognition/Splitted/TEST/sunflower/15054752730_fcf54d475e_m.jpg',\n",
        "                     target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "\n",
        "image_tensor = np.vstack([x])\n",
        "classes = model.predict(image_tensor)\n",
        "print(classes)\n",
        "max_arg = np.argmax(classes)\n",
        "print(categories[max_arg])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3.8019877e-24 2.7714291e-01 4.2396702e-12 0.0000000e+00 7.2285712e-01]]\n",
            "tulip\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}